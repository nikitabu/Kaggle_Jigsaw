{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blend Predictions through Optimized Weighted Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from scipy.stats.mstats import gmean, hmean\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_predictions(prediction_dir, mode='valid', valid_columns=None, stacking_mode='flat'):\n",
    "    valid_labels = pd.read_csv(os.path.join(prediction_dir, 'valid_split.csv'))\n",
    "    sample_submission = pd.read_csv(os.path.join(prediction_dir, 'sample_submission.csv'))\n",
    "    \n",
    "    predictions = []\n",
    "    filenames = []\n",
    "    \n",
    "    for filepath in sorted(glob.glob('{}/{}/*'.format(prediction_dir, mode))):\n",
    "        prediction_single = pd.read_csv(filepath)\n",
    "        prediction_single.drop('id', axis=1, inplace=True)\n",
    "        predictions.append(prediction_single)\n",
    "        filenames.append(filepath.split(\"\\\\\")[-1])\n",
    "\n",
    "    return predictions, sample_submission, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL_COLUMNS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "SINGLE_DIR = 'single_model_predictions'\n",
    "SAMPLE_SUBMISSION_PATH = 'single_model_predictions/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_split  = pd.read_csv('single_model_predictions/valid_split.csv').drop('comment_text', axis=1)\n",
    "valid_actual = pd.read_csv('single_model_predictions/valid_split.csv').drop('comment_text', axis=1)\n",
    "\n",
    "valid_predictions, _, valid_names = read_predictions(SINGLE_DIR, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_scores = pd.DataFrame(columns=['name', 'score', 'stddev'])\n",
    "\n",
    "for prediction, name in zip(valid_predictions, valid_names):\n",
    "    scores = []\n",
    "\n",
    "    for label in LABEL_COLUMNS:\n",
    "        score = roc_auc_score(valid_actual[label], prediction[label])\n",
    "        #print(label + ' score = ' + str(score))\n",
    "        scores.append(score)\n",
    "    \n",
    "    pred_scores = pred_scores.append({'name':name, 'score':np.mean(scores), 'stddev':np.std(scores)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18_03_11_LSTM_Valid.csv</td>\n",
       "      <td>0.990253</td>\n",
       "      <td>0.004114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18_03_11_DPCNN_SCNN_GRU_Valid.csv</td>\n",
       "      <td>0.990140</td>\n",
       "      <td>0.003719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18_03_11_FastTextGRU_Valid.csv</td>\n",
       "      <td>0.990036</td>\n",
       "      <td>0.003918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18_03_17_Pavel_Valid.csv</td>\n",
       "      <td>0.989998</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wordbatch_Merged_VALID.csv</td>\n",
       "      <td>0.987584</td>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18_02_16_BagOfWords_TFIDF_LogisticRegression_V...</td>\n",
       "      <td>0.985529</td>\n",
       "      <td>0.004436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18_02_18_pooledgru_valid.csv</td>\n",
       "      <td>0.984768</td>\n",
       "      <td>0.003736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lvl0_lgbm_clean_VALID.csv</td>\n",
       "      <td>0.983589</td>\n",
       "      <td>0.006970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>char_vdcnn_valid.csv</td>\n",
       "      <td>0.973076</td>\n",
       "      <td>0.012755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name     score    stddev\n",
       "4                            18_03_11_LSTM_Valid.csv  0.990253  0.004114\n",
       "2                  18_03_11_DPCNN_SCNN_GRU_Valid.csv  0.990140  0.003719\n",
       "3                     18_03_11_FastTextGRU_Valid.csv  0.990036  0.003918\n",
       "5                           18_03_17_Pavel_Valid.csv  0.989998  0.003000\n",
       "6                         Wordbatch_Merged_VALID.csv  0.987584  0.004614\n",
       "0  18_02_16_BagOfWords_TFIDF_LogisticRegression_V...  0.985529  0.004436\n",
       "1                       18_02_18_pooledgru_valid.csv  0.984768  0.003736\n",
       "8                          lvl0_lgbm_clean_VALID.csv  0.983589  0.006970\n",
       "7                               char_vdcnn_valid.csv  0.973076  0.012755"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_scores.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blend Validation Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    for label in LABEL_COLUMNS:\n",
    "        valid_split[label] = np.average([prediction[label].values for prediction in valid_predictions], axis=0, weights=x)    \n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    for label in LABEL_COLUMNS:\n",
    "        score = roc_auc_score(valid_actual[label], valid_split[label])\n",
    "        scores.append(score)\n",
    "        \n",
    "    return(-np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [11:34<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992175196836278\n",
      "[0.08792799 0.0310167  0.0315641  0.02459024 0.28716949 0.21458821\n",
      " 0.20837474 0.02844955 0.08631898]\n"
     ]
    }
   ],
   "source": [
    "num_times = 2000;\n",
    "coef_dir = 1;\n",
    "\n",
    "best_score = 0;\n",
    "best_variables = [];\n",
    "\n",
    "for x in tqdm(range(num_times)):\n",
    "    \n",
    "    res = minimize(objective,\n",
    "    #               x0 = [1/len(valid_predictions) for x in range(len(valid_predictions))],\n",
    "                   x0 = np.random.dirichlet(np.ones((len(valid_predictions)))*coef_dir, size=1)[0],\n",
    "                   bounds = [(0, 1) for x in range(len(valid_predictions))],\n",
    "                   constraints = {'type': 'eq', \n",
    "                                  'fun': lambda x: (sum(x)-1)}, \n",
    "                   method='SLSQP')\n",
    "    \n",
    "    if best_score < -res.fun:\n",
    "        best_score = -res.fun\n",
    "        best_variables = res.x\n",
    "\n",
    "print(best_score)\n",
    "print(best_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992175196836278\n",
      "[0.08792799 0.0310167  0.0315641  0.02459024 0.28716949 0.21458821\n",
      " 0.20837474 0.02844955 0.08631898]\n"
     ]
    }
   ],
   "source": [
    "the_best_score     = best_score\n",
    "the_best_variables = best_variables\n",
    "\n",
    "print(the_best_score)\n",
    "print(the_best_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blend Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions, sample_submission, _ = read_predictions(SINGLE_DIR, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for label in LABEL_COLUMNS:\n",
    "    sample_submission[label] = np.average([prediction[label].values for prediction in predictions], axis=0, weights=the_best_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.945151</td>\n",
       "      <td>0.465507</td>\n",
       "      <td>0.925977</td>\n",
       "      <td>0.216399</td>\n",
       "      <td>0.893929</td>\n",
       "      <td>0.458318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.106829</td>\n",
       "      <td>0.105170</td>\n",
       "      <td>0.103594</td>\n",
       "      <td>0.104166</td>\n",
       "      <td>0.105452</td>\n",
       "      <td>0.105509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.108799</td>\n",
       "      <td>0.104087</td>\n",
       "      <td>0.106297</td>\n",
       "      <td>0.104646</td>\n",
       "      <td>0.103966</td>\n",
       "      <td>0.104882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.101106</td>\n",
       "      <td>0.103449</td>\n",
       "      <td>0.102196</td>\n",
       "      <td>0.104258</td>\n",
       "      <td>0.102420</td>\n",
       "      <td>0.103436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.110721</td>\n",
       "      <td>0.103960</td>\n",
       "      <td>0.105147</td>\n",
       "      <td>0.104102</td>\n",
       "      <td>0.105305</td>\n",
       "      <td>0.105214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.945151      0.465507  0.925977  0.216399  0.893929   \n",
       "1  0000247867823ef7  0.106829      0.105170  0.103594  0.104166  0.105452   \n",
       "2  00013b17ad220c46  0.108799      0.104087  0.106297  0.104646  0.103966   \n",
       "3  00017563c3f7919a  0.101106      0.103449  0.102196  0.104258  0.102420   \n",
       "4  00017695ad8997eb  0.110721      0.103960  0.105147  0.104102  0.105305   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.458318  \n",
       "1       0.105509  \n",
       "2       0.104882  \n",
       "3       0.103436  \n",
       "4       0.105214  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENSEMBLE_SUBMISSION_PATH = 'submissions/18_03_19_OptimizedWeightedAverage_Updated.csv'\n",
    "\n",
    "sample_submission.to_csv(ENSEMBLE_SUBMISSION_PATH, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
