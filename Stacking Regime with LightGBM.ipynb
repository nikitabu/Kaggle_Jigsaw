{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Regime with Engineered Features and LightGBM\n",
    "\n",
    "Portions of code resued from:\n",
    "\n",
    "https://www.kaggle.com/hhstrand/oof-stacking-regime/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning, module='sklearn')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import stopwords\n",
    "from time import time\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "text_file = open(\"compiled_bad_words.txt\", \"r\");\n",
    "bad_words = text_file.read().split('\\n')\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# FEATURE ENGINEERING #\n",
    "#######################\n",
    "\"\"\"\n",
    "Main function\n",
    "Input: pandas Series and a feature engineering function\n",
    "Output: pandas Series\n",
    "\"\"\"\n",
    "def engineer_feature(series, func, normalize=True):\n",
    "    feature = series.apply(func)\n",
    "       \n",
    "    if normalize:\n",
    "        feature = pd.Series(z_normalize(feature.values.reshape(-1,1)).reshape(-1,))\n",
    "    feature.name = func.__name__ \n",
    "    return feature\n",
    "\n",
    "\"\"\"\n",
    "Engineer features\n",
    "Input: pandas Series and a list of feature engineering functions\n",
    "Output: pandas DataFrame\n",
    "\"\"\"\n",
    "def engineer_features(series, funclist, normalize=True):\n",
    "    features = pd.DataFrame()\n",
    "    for func in funclist:\n",
    "        print(str(func))\n",
    "        feature = engineer_feature(series, func, normalize)\n",
    "        features[feature.name] = feature\n",
    "    return features\n",
    "\n",
    "\"\"\"\n",
    "Normalizer\n",
    "Input: NumPy array\n",
    "Output: NumPy array\n",
    "\"\"\"\n",
    "scaler = StandardScaler()\n",
    "def z_normalize(data):\n",
    "    scaler.fit(data)\n",
    "    return scaler.transform(data)\n",
    "    \n",
    "################\n",
    "### Features ###\n",
    "################\n",
    "\n",
    "def asterix_freq(x):\n",
    "    return x.count('!')/len(x)\n",
    "\n",
    "def uppercase_freq(x):\n",
    "    return len(re.findall(r'[A-Z]', x))/len(x)\n",
    "\n",
    "def sentence_count(x):\n",
    "    return len(re.findall(\"\\n\", str(x)))+1\n",
    "\n",
    "def word_count(x):\n",
    "    return len(str(x).split())\n",
    "\n",
    "def unique_word_count(x):\n",
    "    return len(set(str(x).split()))\n",
    "\n",
    "def count_letters(x):\n",
    "    return len(str(x))\n",
    "\n",
    "def count_punctuations(x):\n",
    "    return len([c for c in str(x) if c in string.punctuation])\n",
    "\n",
    "def count_words_title(x):\n",
    "    return len([w for w in str(x).split() if w.istitle()])\n",
    "\n",
    "def count_stopwords(x):\n",
    "    return len([w for w in str(x).lower().split() if w in eng_stopwords])\n",
    "\n",
    "def mean_word_len(x):\n",
    "    words = [len(w) for w in str(x).split()]\n",
    "\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.mean(words)\n",
    "\n",
    "########################\n",
    "### Derived Features ###\n",
    "########################\n",
    "\n",
    "def unique_word_ratio(x):\n",
    "    wc = word_count(x)\n",
    "    \n",
    "    if wc == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return unique_word_count(x)/wc\n",
    "\n",
    "def percent_ratio(x):\n",
    "    wc = word_count(x)\n",
    "    \n",
    "    if wc == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return count_punctuations(x)/wc\n",
    "\n",
    "def words_per_sentence(x):\n",
    "    sc = sentence_count(x)\n",
    "    \n",
    "    if sc == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return word_count(x)/sc\n",
    "\n",
    "####################\n",
    "### New Features ###\n",
    "####################\n",
    "\n",
    "def count_bad_words(x):\n",
    "    return len([w for w in str(x).lower().split() if w in bad_words])\n",
    "\n",
    "def contains_ip(x):\n",
    "    return len(re.findall(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', x))\n",
    "\n",
    "def contains_link(x):\n",
    "    return len(re.findall('http://.*com', x))\n",
    "\n",
    "def contains_utc(x):\n",
    "    return len(re.findall('UTC', x))\n",
    "\n",
    "def count_nonalphanum(x):\n",
    "    return len(re.sub(r'[a-zA-Z0-9 ]*', '', x))\n",
    "\n",
    "def contains_article_id(x):\n",
    "    return len(re.findall(\"\\d:\\d\\d\\s{0,5}$\", x))\n",
    "\n",
    "def contains_user(x):\n",
    "    return len(re.findall(\"\\[\\[User(.*)\\|\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import submission and OOF files\n",
    "\"\"\"\n",
    "def get_subs(nums):\n",
    "    subs = np.hstack([np.array(pd.read_csv(\"../input/trained-models/sub\" + str(num) + \".csv\")[LABELS]) for num in subnums])\n",
    "    oofs = np.hstack([np.array(pd.read_csv(\"../input/trained-models/oof\" + str(num) + \".csv\")[LABELS]) for num in subnums])\n",
    "    return subs, oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_predictions(prediction_dir, valid_columns=None, stacking_mode='flat'):\n",
    "    \n",
    "    predictions = []\n",
    "    filenames = []\n",
    "    \n",
    "    for filepath in sorted(glob.glob('{}/*'.format(prediction_dir))):\n",
    "        prediction_single = pd.read_csv(filepath)\n",
    "        prediction_single.drop('id', axis=1, inplace=True)\n",
    "        predictions.append(prediction_single)\n",
    "        filenames.append(filepath.split(\"\\\\\")[-1])\n",
    "\n",
    "    return np.hstack(predictions), filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oofs, oofs_names = read_predictions('valid')\n",
    "subs, sub_names  = read_predictions('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15958, 54)\n",
      "(153164, 54)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(oofs))\n",
    "print(np.shape(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18_02_16_BagOfWords_TFIDF_LogisticRegression_Test.csv',\n",
       " '18_02_18_pooledgru_test.csv',\n",
       " '18_03_11_DPCNN_SCNN_GRU_Test.csv',\n",
       " '18_03_11_FastTextGRU_Test.csv',\n",
       " '18_03_11_LSTM_Test.csv',\n",
       " '18_03_17_Pavel_Test.csv',\n",
       " 'Wordbatch_Merged_TEST.csv',\n",
       " 'char_vdcnn_test.csv',\n",
       " 'lvl0_lgbm_clean_TEST.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('valid_split.csv').fillna(' ')\n",
    "test  = pd.read_csv('test.csv').fillna(' ')\n",
    "sub   = pd.read_csv('sample_submission.csv')\n",
    "INPUT_COLUMN = \"comment_text\"\n",
    "LABELS = train.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function asterix_freq at 0x0000024BEB19DD08>\n",
      "<function uppercase_freq at 0x0000024BEB19DC80>\n",
      "<function unique_word_count at 0x0000024BEB19DB70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function count_letters at 0x0000024BEB19DAE8>\n",
      "<function count_punctuations at 0x0000024BEB19D9D8>\n",
      "<function count_words_title at 0x0000024BEB19D8C8>\n",
      "<function count_stopwords at 0x0000024BEB19D730>\n",
      "<function mean_word_len at 0x0000024BEB19D950>\n",
      "<function unique_word_ratio at 0x0000024BEB19DE18>\n",
      "<function percent_ratio at 0x0000024BEB19D1E0>\n",
      "<function count_bad_words at 0x0000024BEB19DBF8>\n",
      "<function asterix_freq at 0x0000024BEB19DD08>\n",
      "<function uppercase_freq at 0x0000024BEB19DC80>\n",
      "<function unique_word_count at 0x0000024BEB19DB70>\n",
      "<function count_letters at 0x0000024BEB19DAE8>\n",
      "<function count_punctuations at 0x0000024BEB19D9D8>\n",
      "<function count_words_title at 0x0000024BEB19D8C8>\n",
      "<function count_stopwords at 0x0000024BEB19D730>\n",
      "<function mean_word_len at 0x0000024BEB19D950>\n",
      "<function unique_word_ratio at 0x0000024BEB19DE18>\n",
      "<function percent_ratio at 0x0000024BEB19D1E0>\n",
      "<function count_bad_words at 0x0000024BEB19DBF8>\n"
     ]
    }
   ],
   "source": [
    "feature_functions = [asterix_freq, uppercase_freq, unique_word_count, count_letters,\n",
    "                     count_punctuations, count_words_title, count_stopwords, mean_word_len, \n",
    "                     unique_word_ratio, percent_ratio, count_bad_words]\n",
    "\n",
    "#feature_functions = [asterix_freq, uppercase_freq, sentence_count, word_count, unique_word_count, count_letters,\n",
    "#                     count_punctuations, count_words_title, count_stopwords, mean_word_len, \n",
    "#                     contains_ip, contains_link, contains_utc, count_nonalphanum, contains_article_id, contains_user,\n",
    "#                     unique_word_ratio, percent_ratio, words_per_sentence,\n",
    "#                     count_bad_words]\n",
    "\n",
    "#feature_functions = [asterix_freq, uppercase_freq, sentence_count, word_count, unique_word_count, count_letters,\n",
    "#                     count_punctuations, count_words_title, count_stopwords, count_bad_words, contains_ip]\n",
    "\n",
    "features = [f.__name__ for f in feature_functions]\n",
    "F_train = engineer_features(train[INPUT_COLUMN], feature_functions)\n",
    "F_test = engineer_features(test[INPUT_COLUMN], feature_functions)\n",
    "\n",
    "X_train = np.hstack([F_train[features].as_matrix(), oofs])\n",
    "X_test = np.hstack([F_test[features].as_matrix(), subs])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacker = lgb.LGBMClassifier(max_depth=3, metric=\"auc\", n_estimators=125, num_leaves=10, boosting_type=\"gbdt\", \n",
    "                             learning_rate=0.1, feature_fraction=0.45, colsample_bytree=0.45, bagging_fraction=0.8, \n",
    "                             bagging_freq=5, reg_lambda=0.2, is_unbalance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "Average Score = 0.9874565280189438\n",
      "Standard Deviation = 0.00213260639270309\n",
      "\n",
      "\n",
      "severe_toxic\n",
      "Average Score = 0.9834189037159307\n",
      "Standard Deviation = 0.015176021173588022\n",
      "\n",
      "\n",
      "obscene\n",
      "Average Score = 0.9942592410636555\n",
      "Standard Deviation = 0.0005766126694572562\n",
      "\n",
      "\n",
      "threat\n",
      "Average Score = 0.9936625126540302\n",
      "Standard Deviation = 0.006356515833338479\n",
      "\n",
      "\n",
      "insult\n",
      "Average Score = 0.986933081412254\n",
      "Standard Deviation = 0.0036210487582391355\n",
      "\n",
      "\n",
      "identity_hate\n",
      "Average Score = 0.9781690739092855\n",
      "Standard Deviation = 0.016752454780656414\n",
      "\n",
      "\n",
      "\n",
      "Overall\n",
      "Average Score = 0.9873165567956832\n",
      "Overall Standard Deviation = 0.005590271439457984\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for label in LABELS:\n",
    "    score = cross_val_score(stacker, X_train, train[label], cv=5, scoring='roc_auc')\n",
    "    print(str(label) + '\\nAverage Score = {}\\nStandard Deviation = {}'.format(np.mean(score), np.std(score)))\n",
    "    print(\"\\n\")\n",
    "    scores.append(np.mean(score))\n",
    "    stacker.fit(X_train, train[label])\n",
    "    #sub[label] = stacker.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "print('\\nOverall\\nAverage Score = {}\\nOverall Standard Deviation = {}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "RandomizedSearchCV took 2564.74 seconds for 1000 candidates parameter settings.\n",
      "Best Score = 0.9882547805834225\n",
      "Best Parameters = {'reg_lambda': 10.0, 'num_leaves': 16, 'n_estimators': 64, 'max_depth': 4, 'bagging_freq': 128, 'bagging_fraction': 0.9}\n",
      "\n",
      "\n",
      "severe_toxic\n",
      "RandomizedSearchCV took 1880.94 seconds for 1000 candidates parameter settings.\n",
      "Best Score = 0.9915554230214446\n",
      "Best Parameters = {'reg_lambda': 10.0, 'num_leaves': 4096, 'n_estimators': 64, 'max_depth': 16, 'bagging_freq': 32, 'bagging_fraction': 0.7}\n",
      "\n",
      "\n",
      "obscene\n",
      "RandomizedSearchCV took 2070.87 seconds for 1000 candidates parameter settings.\n",
      "Best Score = 0.995019472432022\n",
      "Best Parameters = {'reg_lambda': 100.0, 'num_leaves': 512, 'n_estimators': 64, 'max_depth': 4, 'bagging_freq': 1, 'bagging_fraction': 0.8}\n",
      "\n",
      "\n",
      "threat\n",
      "RandomizedSearchCV took 1489.02 seconds for 1000 candidates parameter settings.\n",
      "Best Score = 0.9966224102531108\n",
      "Best Parameters = {'reg_lambda': 1000.0, 'num_leaves': 32, 'n_estimators': 256, 'max_depth': 32, 'bagging_freq': 64, 'bagging_fraction': 0.8}\n",
      "\n",
      "\n",
      "insult\n",
      "RandomizedSearchCV took 2305.63 seconds for 1000 candidates parameter settings.\n",
      "Best Score = 0.988764389566484\n",
      "Best Parameters = {'reg_lambda': 100.0, 'num_leaves': 128, 'n_estimators': 256, 'max_depth': 32, 'bagging_freq': 2, 'bagging_fraction': 0.8}\n",
      "\n",
      "\n",
      "identity_hate\n",
      "RandomizedSearchCV took 1718.09 seconds for 1000 candidates parameter settings.\n",
      "Best Score = 0.9911395043774031\n",
      "Best Parameters = {'reg_lambda': 1000.0, 'num_leaves': 16, 'n_estimators': 64, 'max_depth': 64, 'bagging_freq': 2, 'bagging_fraction': 0.6}\n",
      "\n",
      "\n",
      "\n",
      "Average Score = 0.9918926633723145\n",
      "Standard Deviation = 0.003050920849189196\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    \"max_depth\":                [2, 4, 8, 16, 32, 64],\n",
    "#    \"learning_rate\":            [1e-3, 1e-2, 1e-1, 1e0, 1e1],\n",
    "    \"num_leaves\":               [8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "    \"reg_lambda\":               [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "    \"n_estimators\":             [64, 128, 256, 512, 1024],\n",
    "    \"bagging_freq\":             [1, 2, 4, 8, 16, 32, 64, 128, 256],\n",
    "    \"bagging_fraction\":         [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "#    \"max_bin\":                  [2, 4, 8, 16, 32, 64, 128, 256],\n",
    "#    \"feature_fraction\":         [0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "#    \"colsample_bytree\":         [0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "n_iter_search = 1000;\n",
    "\n",
    "scores = []\n",
    "\n",
    "stackerCV = lgb.LGBMClassifier(#max_depth=3, \n",
    "                               metric=\"auc\", \n",
    "                               #n_estimators=128, \n",
    "                               #num_leaves=10, \n",
    "                               boosting_type=\"gbdt\", \n",
    "                               learning_rate=0.1, \n",
    "                               feature_fraction=0.45, \n",
    "                               colsample_bytree=0.45, \n",
    "                               #bagging_fraction=0.8, \n",
    "                               #bagging_freq=5 \n",
    "                               #reg_lambda=0.2\n",
    "                               )\n",
    "\n",
    "for label in LABELS:\n",
    "    print(label)\n",
    "\n",
    "    random_search = RandomizedSearchCV(stackerCV, param_distributions=param_dist, n_iter=n_iter_search, cv=5, \n",
    "                                       scoring='roc_auc', n_jobs=2, verbose=0)\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    random_search.fit(X_train, train[label])\n",
    "\n",
    "    scores.append(random_search.best_score_)\n",
    "    \n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "          \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "\n",
    "    print(\"Best Score = \" + str(random_search.best_score_))\n",
    "\n",
    "    print(\"Best Parameters = \" + str(random_search.best_params_))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    sub[label] = random_search.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "print('\\nAverage Score = {}\\nStandard Deviation = {}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission/18_03_19_OOFstacking_LightGBM_RandomSearchCV_localAUC99202.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
